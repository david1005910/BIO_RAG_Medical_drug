"""ë°ì´í„° ë™ê¸°í™” ì„œë¹„ìŠ¤ - API â†’ DB â†’ Vector Index (PGVector + Qdrant)"""
import logging
from typing import List, Optional

from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select

from app.external.data_go_kr import DataGoKrClient, DrugInfo
from app.models.drug import Drug
from app.services.data_preprocessor import DrugDataPreprocessor
from app.services.embedding import get_embedding_service
from app.services.vector_db import VectorDBService
from app.services.qdrant_service import get_qdrant_service
from app.services.splade_service import get_splade_service
from app.core.config import settings

logger = logging.getLogger(__name__)


class DataSyncService:
    """ë°ì´í„° ë™ê¸°í™” ì„œë¹„ìŠ¤"""

    def __init__(self, session: AsyncSession):
        self.session = session
        self.api_client = DataGoKrClient()
        self.preprocessor = DrugDataPreprocessor()
        self.embedding_service = get_embedding_service()

    async def sync_drugs(
        self,
        max_pages: int = 10,
        num_of_rows: int = 100,
        build_vectors: bool = True,
    ) -> dict:
        """ê³µê³µë°ì´í„° APIì—ì„œ ì˜ì•½í’ˆ ë°ì´í„° ë™ê¸°í™”

        Args:
            max_pages: ìˆ˜ì§‘í•  ìµœëŒ€ í˜ì´ì§€ ìˆ˜
            num_of_rows: í˜ì´ì§€ë‹¹ ê²°ê³¼ ìˆ˜
            build_vectors: ë²¡í„° ì¸ë±ìŠ¤ë„ í•¨ê»˜ êµ¬ì¶•í• ì§€ ì—¬ë¶€

        Returns:
            ë™ê¸°í™” ê²°ê³¼ í†µê³„
        """
        stats = {
            "fetched": 0,
            "processed": 0,
            "saved": 0,
            "vectors_created": 0,
            "errors": 0,
        }

        try:
            # 1. APIì—ì„œ ë°ì´í„° ìˆ˜ì§‘
            logger.info(f"ğŸ“¥ APIì—ì„œ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ (ìµœëŒ€ {max_pages} í˜ì´ì§€)...")
            async with self.api_client as client:
                drugs = await client.collect_all_drugs(
                    max_pages=max_pages,
                    num_of_rows=num_of_rows,
                )
            stats["fetched"] = len(drugs)

            if not drugs:
                logger.warning("ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return stats

            # 2. ë°ì´í„° ì „ì²˜ë¦¬
            logger.info("ğŸ”„ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")
            processed = self.preprocessor.preprocess_batch(drugs)
            stats["processed"] = len(processed)

            # 3. DBì— ì €ì¥
            logger.info("ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì¤‘...")
            saved_count = await self._save_drugs(processed)
            stats["saved"] = saved_count

            # 4. ë²¡í„° ì¸ë±ìŠ¤ êµ¬ì¶• (ì„ íƒ)
            if build_vectors:
                logger.info("ğŸ§  ë²¡í„° ì¸ë±ìŠ¤ êµ¬ì¶• ì¤‘...")
                vector_count = await self._build_vectors(processed)
                stats["vectors_created"] = vector_count

            logger.info(f"âœ… ë™ê¸°í™” ì™„ë£Œ: {stats}")
            return stats

        except Exception as e:
            logger.error(f"ë™ê¸°í™” ì‹¤íŒ¨: {e}")
            stats["errors"] += 1
            raise

    async def _save_drugs(self, processed: List[dict]) -> int:
        """ì˜ì•½í’ˆ ë°ì´í„°ë¥¼ DBì— ì €ì¥ (upsert)"""
        saved_count = 0

        for item in processed:
            try:
                # ê¸°ì¡´ ë°ì´í„° í™•ì¸
                existing = await self.session.execute(
                    select(Drug).where(Drug.id == item["id"])
                )
                drug = existing.scalar_one_or_none()

                if drug:
                    # ì—…ë°ì´íŠ¸
                    for key, value in item.items():
                        if key != "document" and hasattr(drug, key):
                            setattr(drug, key, value)
                else:
                    # ìƒˆë¡œ ìƒì„±
                    drug = Drug(
                        id=item["id"],
                        item_name=item["item_name"],
                        entp_name=item["entp_name"],
                        efficacy=item["efficacy"],
                        use_method=item["use_method"],
                        warning_info=item["warning_info"],
                        caution_info=item["caution_info"],
                        interaction=item["interaction"],
                        side_effects=item["side_effects"],
                        storage_method=item["storage_method"],
                    )
                    self.session.add(drug)

                saved_count += 1

            except Exception as e:
                logger.warning(f"ì €ì¥ ì‹¤íŒ¨: {item.get('item_name')} - {e}")
                continue

        await self.session.commit()
        return saved_count

    async def _build_vectors(self, processed: List[dict]) -> int:
        """ë²¡í„° ì¸ë±ìŠ¤ êµ¬ì¶• (PGVector + Qdrant)"""
        vector_db = VectorDBService(self.session)

        # ê¸°ì¡´ ë²¡í„° ì‚­ì œ
        await vector_db.delete_all()

        # ë¬¸ì„œì™€ ID ì¶”ì¶œ
        documents = [item["document"] for item in processed]
        drug_ids = [item["id"] for item in processed]

        # ë°°ì¹˜ ì„ë² ë”© ìƒì„± (Dense)
        logger.info("ğŸ§  Dense ì„ë² ë”© ìƒì„± ì¤‘...")
        embeddings = await self.embedding_service.embed_batch(documents)

        # PGVectorì— ì €ì¥
        vectors = [
            {
                "drug_id": drug_id,
                "embedding": embedding,
                "document": document,
            }
            for drug_id, embedding, document in zip(drug_ids, embeddings, documents)
        ]
        pgvector_count = await vector_db.add_vectors_batch(vectors)

        # Qdrant + SPLADE ì¸ë±ì‹± (í™œì„±í™”ëœ ê²½ìš°)
        if settings.ENABLE_QDRANT:
            await self._build_qdrant_vectors(processed, embeddings)

        return pgvector_count

    async def _build_qdrant_vectors(
        self,
        processed: List[dict],
        dense_embeddings: List[List[float]],
    ) -> int:
        """Qdrant ë²¡í„° ì¸ë±ìŠ¤ êµ¬ì¶• (Dense + Sparse)"""
        import gc
        try:
            qdrant_service = get_qdrant_service()
            splade_service = get_splade_service()

            # Qdrant ì—°ê²° í™•ì¸
            if not qdrant_service._initialized:
                await qdrant_service.connect()
                await qdrant_service.create_collection(recreate=True)

            # SPLADE Sparse ì„ë² ë”© ìƒì„± (ì‘ì€ ë°°ì¹˜ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½)
            logger.info("ğŸ”§ SPLADE Sparse ì„ë² ë”© ìƒì„± ì¤‘...")
            documents = [item["document"] for item in processed]
            sparse_embeddings = await splade_service.encode_batch(documents, batch_size=8)
            gc.collect()  # ë©”ëª¨ë¦¬ ì •ë¦¬

            # Qdrant ë¬¸ì„œ ì¤€ë¹„
            qdrant_docs = [
                {
                    "drug_id": item["id"],
                    "item_name": item.get("item_name", ""),
                    "entp_name": item.get("entp_name", ""),
                    "efficacy": item.get("efficacy", ""),
                    "use_method": item.get("use_method", ""),
                    "caution_info": item.get("caution_info", ""),
                    "side_effects": item.get("side_effects", ""),
                }
                for item in processed
            ]

            # Qdrantì— ì—…ì„œíŠ¸
            logger.info("ğŸ“¤ Qdrantì— ë²¡í„° ì—…ì„œíŠ¸ ì¤‘...")
            qdrant_count = await qdrant_service.upsert_documents(
                documents=qdrant_docs,
                dense_vectors=dense_embeddings,
                sparse_vectors=sparse_embeddings,
            )

            logger.info(f"âœ… Qdrant ì¸ë±ì‹± ì™„ë£Œ: {qdrant_count}ê°œ")
            return qdrant_count

        except Exception as e:
            logger.error(f"âŒ Qdrant ì¸ë±ì‹± ì‹¤íŒ¨: {e}")
            return 0

    async def rebuild_vectors(self) -> int:
        """ê¸°ì¡´ DB ë°ì´í„°ë¡œ ë²¡í„° ì¸ë±ìŠ¤ ì¬êµ¬ì¶• (PGVector + Qdrant)"""
        vector_db = VectorDBService(self.session)

        # DBì—ì„œ ëª¨ë“  ì˜ì•½í’ˆ ì¡°íšŒ
        result = await self.session.execute(select(Drug))
        drugs = result.scalars().all()

        if not drugs:
            logger.warning("DBì— ì˜ì•½í’ˆ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return 0

        # ë¬¸ì„œ ìƒì„± (Qdrantìš© ë©”íƒ€ë°ì´í„° í¬í•¨)
        processed = []
        for drug in drugs:
            document = self.preprocessor._create_document(
                drug.item_name,
                drug.entp_name or "",
                drug.efficacy or "",
                drug.use_method or "",
                drug.warning_info or "",
                drug.caution_info or "",
                drug.interaction or "",
                drug.side_effects or "",
                drug.storage_method or "",
            )
            processed.append({
                "id": drug.id,
                "document": document,
                "item_name": drug.item_name,
                "entp_name": drug.entp_name or "",
                "efficacy": drug.efficacy or "",
                "use_method": drug.use_method or "",
                "caution_info": drug.caution_info or "",
                "side_effects": drug.side_effects or "",
            })

        # ê¸°ì¡´ ë²¡í„° ì‚­ì œ
        await vector_db.delete_all()

        # ì„ë² ë”© ìƒì„± ë° ì €ì¥
        documents = [item["document"] for item in processed]
        drug_ids = [item["id"] for item in processed]

        logger.info("ğŸ§  Dense ì„ë² ë”© ìƒì„± ì¤‘...")
        embeddings = await self.embedding_service.embed_batch(documents)

        vectors = [
            {
                "drug_id": drug_id,
                "embedding": embedding,
                "document": document,
            }
            for drug_id, embedding, document in zip(drug_ids, embeddings, documents)
        ]

        pgvector_count = await vector_db.add_vectors_batch(vectors)

        # Qdrant + SPLADE ì¸ë±ì‹± (í™œì„±í™”ëœ ê²½ìš°)
        if settings.ENABLE_QDRANT:
            await self._build_qdrant_vectors(processed, embeddings)

        return pgvector_count
