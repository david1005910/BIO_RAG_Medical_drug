"""BGE-M3 Sparse Embedding ì„œë¹„ìŠ¤ - ë‹¤êµ­ì–´(í•œêµ­ì–´) ì§€ì›

ê¸°ì¡´ SPLADE ëª¨ë¸ì€ í•œêµ­ì–´ë¥¼ ìëª¨ë¡œ ë¶„í•´í•˜ì—¬ ì˜ë¯¸ ì—†ëŠ” ê²°ê³¼ë¥¼ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤.
BGE-M3ëŠ” 100+ ì–¸ì–´ë¥¼ ì§€ì›í•˜ë©°, í•œêµ­ì–´ sparse embeddingì´ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤.

ì°¸ê³ : https://huggingface.co/BAAI/bge-m3
"""
import logging
from typing import Dict, List, Optional, Any
import asyncio

from app.core.config import settings

logger = logging.getLogger(__name__)


class SPLADEService:
    """BGE-M3 Sparse Embedding ì„œë¹„ìŠ¤ (SPLADE ëŒ€ì²´)

    BGE-M3 (BAAI/bge-m3)ë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ Sparse ë²¡í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    - 100+ ì–¸ì–´ ì§€ì› (í•œêµ­ì–´ í¬í•¨)
    - Dense + Sparse + ColBERT ì„ë² ë”© ë™ì‹œ ì§€ì›
    - ìµœëŒ€ 8192 í† í° ì²˜ë¦¬ ê°€ëŠ¥

    ì ìˆ˜ ì²´ê³„:
    - BGE-M3 lexical weight: í† í°ë³„ ê°€ì¤‘ì¹˜
    - ì •ê·œí™”: max_score ê¸°ì¤€ìœ¼ë¡œ 0~1 ìŠ¤ì¼€ì¼ë¡œ ì •ê·œí™”
    """

    def __init__(self, model_name: Optional[str] = None):
        # BGE-M3 ëª¨ë¸ ì‚¬ìš© (SPLADE_MODEL ì„¤ì • ë¬´ì‹œ)
        self.model_name = "BAAI/bge-m3"
        self.model = None
        self._initialized = False
        self._load_failed = False  # ë¡œë”© ì‹¤íŒ¨ í”Œë˜ê·¸ (ì¬ì‹œë„ ë°©ì§€)
        self.max_score = settings.SPLADE_MAX_SCORE  # ì •ê·œí™” ê¸°ì¤€

    async def initialize(self) -> bool:
        """BGE-M3 ëª¨ë¸ ì´ˆê¸°í™”

        Returns:
            ì´ˆê¸°í™” ì„±ê³µ ì—¬ë¶€
        """
        if self._initialized:
            return True

        # ì´ë¯¸ ë¡œë”© ì‹¤íŒ¨í•œ ê²½ìš° ì¬ì‹œë„í•˜ì§€ ì•ŠìŒ
        if self._load_failed:
            return False

        try:
            logger.info(f"ğŸ”§ BGE-M3 ëª¨ë¸ ë¡œë”© ì¤‘: {self.model_name}")

            # ëª¨ë¸ ë¡œë“œ (ë¹„ë™ê¸° ì‹¤í–‰)
            loop = asyncio.get_event_loop()

            def load_model():
                from FlagEmbedding import BGEM3FlagModel
                # use_fp16=True for faster inference (GPU only)
                # CPUì—ì„œëŠ” use_fp16=False ì‚¬ìš©
                import torch
                use_fp16 = torch.cuda.is_available()
                model = BGEM3FlagModel(
                    self.model_name,
                    use_fp16=use_fp16,
                )
                return model

            self.model = await loop.run_in_executor(None, load_model)

            self._initialized = True
            logger.info(f"âœ… BGE-M3 ëª¨ë¸ ë¡œë”© ì™„ë£Œ (í•œêµ­ì–´ ì§€ì›)")
            return True

        except Exception as e:
            logger.error(f"âŒ BGE-M3 ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            self._initialized = False
            self._load_failed = True  # ì¬ì‹œë„ ë°©ì§€
            return False

    async def encode(self, text: str) -> Dict[str, Any]:
        """í…ìŠ¤íŠ¸ë¥¼ BGE-M3 Sparse ë²¡í„°ë¡œ ì¸ì½”ë”©

        Args:
            text: ì¸ì½”ë”©í•  í…ìŠ¤íŠ¸

        Returns:
            Sparse ë²¡í„° ë”•ì…”ë„ˆë¦¬ {"indices": [...], "values": [...]}
        """
        if not self._initialized:
            await self.initialize()

        if not self.model:
            logger.error("BGE-M3 ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return {"indices": [], "values": []}

        try:
            loop = asyncio.get_event_loop()

            def do_encode():
                # BGE-M3 ì¸ì½”ë”© (sparseë§Œ í•„ìš”)
                output = self.model.encode(
                    [text],
                    return_dense=False,
                    return_sparse=True,
                    return_colbert_vecs=False,
                )
                return output

            output = await loop.run_in_executor(None, do_encode)

            # lexical_weightsì—ì„œ sparse ë²¡í„° ì¶”ì¶œ
            # í˜•ì‹: {token_id: weight, ...}
            lexical_weights = output.get("lexical_weights", [{}])[0]

            if not lexical_weights:
                return {"indices": [], "values": []}

            # ë”•ì…”ë„ˆë¦¬ë¥¼ indices/values í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            indices = list(lexical_weights.keys())
            values = list(lexical_weights.values())

            return {
                "indices": indices,
                "values": values,
            }

        except Exception as e:
            logger.error(f"âŒ BGE-M3 ì¸ì½”ë”© ì‹¤íŒ¨: {e}")
            return {"indices": [], "values": []}

    async def encode_batch(
        self,
        texts: List[str],
        batch_size: int = 8,
    ) -> List[Dict[str, Any]]:
        """í…ìŠ¤íŠ¸ ë°°ì¹˜ë¥¼ BGE-M3 Sparse ë²¡í„°ë¡œ ì¸ì½”ë”©

        Args:
            texts: ì¸ì½”ë”©í•  í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
            batch_size: ë°°ì¹˜ í¬ê¸° (ë©”ëª¨ë¦¬ ì œì•½ìœ¼ë¡œ 8 ê¶Œì¥)

        Returns:
            Sparse ë²¡í„° ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
        """
        if not self._initialized:
            await self.initialize()

        if not self.model:
            logger.error("BGE-M3 ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return [{"indices": [], "values": []} for _ in texts]

        results = []

        for i in range(0, len(texts), batch_size):
            batch_texts = texts[i:i + batch_size]

            try:
                loop = asyncio.get_event_loop()

                def do_encode_batch(batch):
                    output = self.model.encode(
                        batch,
                        return_dense=False,
                        return_sparse=True,
                        return_colbert_vecs=False,
                    )
                    return output

                output = await loop.run_in_executor(
                    None, do_encode_batch, batch_texts
                )

                # ê° ë¬¸ì„œì˜ lexical_weights ì²˜ë¦¬
                lexical_weights_list = output.get("lexical_weights", [])

                for lexical_weights in lexical_weights_list:
                    if not lexical_weights:
                        results.append({"indices": [], "values": []})
                        continue

                    indices = list(lexical_weights.keys())
                    values = list(lexical_weights.values())

                    results.append({
                        "indices": indices,
                        "values": values,
                    })

                logger.info(
                    f"ğŸ“ BGE-M3 ë°°ì¹˜ ì¸ì½”ë”©: {i + len(batch_texts)}/{len(texts)} ì™„ë£Œ"
                )

            except Exception as e:
                logger.error(f"âŒ BGE-M3 ë°°ì¹˜ ì¸ì½”ë”© ì‹¤íŒ¨: {e}")
                # ì‹¤íŒ¨í•œ ë°°ì¹˜ëŠ” ë¹ˆ ë²¡í„°ë¡œ ì±„ì›€
                results.extend([{"indices": [], "values": []} for _ in batch_texts])

        logger.info(f"âœ… BGE-M3 ì „ì²´ ì¸ì½”ë”© ì™„ë£Œ: {len(results)}ê°œ")
        return results

    def get_sparse_score(self, sparse_vector: Dict[str, Any]) -> float:
        """Sparse ë²¡í„°ì˜ ì´ ì ìˆ˜ ê³„ì‚°

        Args:
            sparse_vector: sparse ë²¡í„°

        Returns:
            ì´ ì ìˆ˜ (values í•©ê³„)
        """
        values = sparse_vector.get("values", [])
        return sum(values) if values else 0.0

    def normalize_score(self, score: float) -> float:
        """ì ìˆ˜ë¥¼ 0~1 ë²”ìœ„ë¡œ ì •ê·œí™”

        Args:
            score: ì›ë³¸ ì ìˆ˜

        Returns:
            0~1 ë²”ìœ„ë¡œ ì •ê·œí™”ëœ ì ìˆ˜
        """
        normalized = score / self.max_score
        return min(normalized, 1.0)

    async def create_document_text(
        self,
        item_name: str,
        efficacy: Optional[str] = None,
        use_method: Optional[str] = None,
        caution_info: Optional[str] = None,
    ) -> str:
        """ì¸ë±ì‹±ìš© ë¬¸ì„œ í…ìŠ¤íŠ¸ ìƒì„±

        Args:
            item_name: ì œí’ˆëª…
            efficacy: íš¨ëŠ¥íš¨ê³¼
            use_method: ìš©ë²•ìš©ëŸ‰
            caution_info: ì£¼ì˜ì‚¬í•­

        Returns:
            ì¸ì½”ë”©ìš© í…ìŠ¤íŠ¸
        """
        parts = [item_name or ""]

        if efficacy:
            parts.append(efficacy)
        if use_method:
            parts.append(use_method[:300])  # ìš©ë²•ì€ ì•ë¶€ë¶„ë§Œ
        if caution_info:
            parts.append(caution_info[:200])  # ì£¼ì˜ì‚¬í•­ë„ ì•ë¶€ë¶„ë§Œ

        return " ".join(parts)


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_splade_service: Optional[SPLADEService] = None


def get_splade_service() -> SPLADEService:
    """Sparse Embedding ì„œë¹„ìŠ¤ ì‹±ê¸€í†¤ ë°˜í™˜"""
    global _splade_service
    if _splade_service is None:
        _splade_service = SPLADEService()
    return _splade_service


async def initialize_splade() -> bool:
    """Sparse Embedding ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
    if not settings.ENABLE_QDRANT:
        logger.info("âš ï¸ BGE-M3 ë¹„í™œì„±í™”ë¨ (ENABLE_QDRANT=false)")
        return False

    service = get_splade_service()
    return await service.initialize()
