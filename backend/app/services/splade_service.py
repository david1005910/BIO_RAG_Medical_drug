"""BGE-M3 Sparse Embedding ì„œë¹„ìŠ¤ - ë‹¤êµ­ì–´(í•œêµ­ì–´) ì§€ì›

ê¸°ì¡´ SPLADE ëª¨ë¸ì€ í•œêµ­ì–´ë¥¼ ìëª¨ë¡œ ë¶„í•´í•˜ì—¬ ì˜ë¯¸ ì—†ëŠ” ê²°ê³¼ë¥¼ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤.
BGE-M3ëŠ” 100+ ì–¸ì–´ë¥¼ ì§€ì›í•˜ë©°, í•œêµ­ì–´ sparse embeddingì´ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤.

ì°¸ê³ : https://huggingface.co/BAAI/bge-m3
"""
import asyncio
import logging
from typing import Any, Dict, List, Optional

from app.core.config import settings

logger = logging.getLogger(__name__)

# ì¦ìƒ ë™ì˜ì–´ ë§¤í•‘ (ì¼ìƒì–´ â†’ ì˜í•™ ìš©ì–´)
# ì¿¼ë¦¬ í™•ì¥ì— ì‚¬ìš©
SYMPTOM_SYNONYMS = {
    # ë³µë¶€/ì†Œí™” ê´€ë ¨
    'ë°°ê°€ ì•„': ['ë³µí†µ', 'ë³µë¶€í†µì¦', 'ìœ„í†µ'],
    'ë°°ì•„íŒŒ': ['ë³µí†µ', 'ìœ„í†µ', 'ì¥í†µ'],
    'ì†ì´': ['ì†Œí™”ë¶ˆëŸ‰', 'ì†ì“°ë¦¼', 'ìœ„ì¥'],
    'ì†ì“°ë ¤': ['ì†ì“°ë¦¼', 'ìœ„ì—¼'],
    'ì²´í–ˆ': ['ì†Œí™”ë¶ˆëŸ‰', 'ì²´ê¸°'],
    'ë”ë¶€ë£©': ['ì†Œí™”ë¶ˆëŸ‰', 'ë³µë¶€íŒ½ë§Œ'],
    # ë‘í†µ/ë¨¸ë¦¬ ê´€ë ¨
    'ë¨¸ë¦¬ê°€ ì•„': ['ë‘í†µ', 'í¸ë‘í†µ'],
    'ë¨¸ë¦¬ì•„íŒŒ': ['ë‘í†µ', 'í¸ë‘í†µ'],
    'ì§€ëˆ': ['ë‘í†µ', 'í¸ë‘í†µ'],
    # ì—´/ê°ê¸° ê´€ë ¨
    'ì—´ë‚˜': ['ë°œì—´', 'ê³ ì—´'],
    'ì—´ì´ë‚˜': ['ë°œì—´', 'ê³ ì—´'],
    'ìœ¼ìŠ¬ìœ¼ìŠ¬': ['ì˜¤í•œ', 'ê°ê¸°'],
    'ì½§ë¬¼ë‚˜': ['ì½§ë¬¼', 'ë¹„ì—¼'],
    'ì½”ë§‰í˜€': ['ì½”ë§‰í˜', 'ë¹„ì—¼'],
    'ê¸°ì¹¨ë‚˜': ['ê¸°ì¹¨', 'í•´ì†Œ'],
    'ëª©ì´ ì•„': ['ì¸í›„í†µ', 'ì¸í›„ì—¼'],
    'ëª©ì•„íŒŒ': ['ì¸í›„í†µ', 'ì¸í›„ì—¼'],
    # ê·¼ê³¨ê²© ê´€ë ¨
    'í—ˆë¦¬ê°€ ì•„': ['ìš”í†µ', 'í—ˆë¦¬í†µì¦'],
    'í—ˆë¦¬ì•„íŒŒ': ['ìš”í†µ'],
    'ì–´ê¹¨ê°€ ì•„': ['ì–´ê¹¨í†µì¦', 'ê²¬í†µ'],
    'ë¬´ë¦ì´ ì•„': ['ë¬´ë¦í†µì¦', 'ê´€ì ˆí†µ'],
    # í”¼ë¶€ ê´€ë ¨
    'ê°€ë ¤ì›Œ': ['ê°€ë ¤ì›€', 'ì†Œì–‘ì¦'],
    'ë‘ë“œëŸ¬ê¸°': ['ë‘ë“œëŸ¬ê¸°', 'ë°œì§„'],
    # ê¸°íƒ€ ì¦ìƒ
    'ì–´ì§€ëŸ¬ì›Œ': ['ì–´ì§€ëŸ¬ì›€', 'í˜„ê¸°ì¦'],
    'ë©”ìŠ¤êº¼ì›Œ': ['ë©”ìŠ¤êº¼ì›€', 'êµ¬ì—­'],
    'í”¼ê³¤': ['í”¼ë¡œ', 'ê¶Œíƒœ'],
    'ì ì´ ì•ˆ': ['ë¶ˆë©´', 'ìˆ˜ë©´ì¥ì• '],
}


class SPLADEService:
    """BGE-M3 Sparse Embedding ì„œë¹„ìŠ¤ (SPLADE ëŒ€ì²´)

    BGE-M3 (BAAI/bge-m3)ë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ Sparse ë²¡í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    - 100+ ì–¸ì–´ ì§€ì› (í•œêµ­ì–´ í¬í•¨)
    - Dense + Sparse + ColBERT ì„ë² ë”© ë™ì‹œ ì§€ì›
    - ìµœëŒ€ 8192 í† í° ì²˜ë¦¬ ê°€ëŠ¥

    ì ìˆ˜ ì²´ê³„:
    - BGE-M3 lexical weight: í† í°ë³„ ê°€ì¤‘ì¹˜
    - ì •ê·œí™”: max_score ê¸°ì¤€ìœ¼ë¡œ 0~1 ìŠ¤ì¼€ì¼ë¡œ ì •ê·œí™”
    """

    def __init__(self, model_name: Optional[str] = None):
        # BGE-M3 ëª¨ë¸ ì‚¬ìš© (SPLADE_MODEL ì„¤ì • ë¬´ì‹œ)
        self.model_name = "BAAI/bge-m3"
        self.model = None
        self._initialized = False
        self._load_failed = False  # ë¡œë”© ì‹¤íŒ¨ í”Œë˜ê·¸ (ì¬ì‹œë„ ë°©ì§€)
        self.max_score = settings.SPLADE_MAX_SCORE  # ì •ê·œí™” ê¸°ì¤€

    async def initialize(self) -> bool:
        """BGE-M3 ëª¨ë¸ ì´ˆê¸°í™”

        Returns:
            ì´ˆê¸°í™” ì„±ê³µ ì—¬ë¶€
        """
        if self._initialized:
            return True

        # ì´ë¯¸ ë¡œë”© ì‹¤íŒ¨í•œ ê²½ìš° ì¬ì‹œë„í•˜ì§€ ì•ŠìŒ
        if self._load_failed:
            return False

        try:
            logger.info(f"ğŸ”§ BGE-M3 ëª¨ë¸ ë¡œë”© ì¤‘: {self.model_name}")

            # ëª¨ë¸ ë¡œë“œ (ë¹„ë™ê¸° ì‹¤í–‰)
            loop = asyncio.get_event_loop()

            def load_model():
                # use_fp16=True for faster inference (GPU only)
                # CPUì—ì„œëŠ” use_fp16=False ì‚¬ìš©
                import torch
                from FlagEmbedding import BGEM3FlagModel
                use_fp16 = torch.cuda.is_available()
                model = BGEM3FlagModel(
                    self.model_name,
                    use_fp16=use_fp16,
                )
                return model

            self.model = await loop.run_in_executor(None, load_model)

            self._initialized = True
            logger.info("âœ… BGE-M3 ëª¨ë¸ ë¡œë”© ì™„ë£Œ (í•œêµ­ì–´ ì§€ì›)")
            return True

        except Exception as e:
            logger.error(f"âŒ BGE-M3 ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            self._initialized = False
            self._load_failed = True  # ì¬ì‹œë„ ë°©ì§€
            return False

    def expand_query(self, query: str) -> str:
        """ì¿¼ë¦¬ë¥¼ ì˜í•™ ìš©ì–´ë¡œ í™•ì¥

        ì¼ìƒì ì¸ ì¦ìƒ í‘œí˜„ì„ ì˜í•™ ìš©ì–´ë¡œ í™•ì¥í•˜ì—¬
        sparse ê²€ìƒ‰ì˜ ë§¤ì¹­ë¥ ì„ ë†’ì…ë‹ˆë‹¤.

        Args:
            query: ì›ë³¸ ì¿¼ë¦¬

        Returns:
            í™•ì¥ëœ ì¿¼ë¦¬ (ì›ë³¸ + ì˜í•™ ìš©ì–´)
        """
        expanded_terms = []

        # ë™ì˜ì–´ ì‚¬ì „ì—ì„œ ë§¤ì¹­ë˜ëŠ” ìš©ì–´ ì°¾ê¸°
        for pattern, synonyms in SYMPTOM_SYNONYMS.items():
            if pattern in query:
                expanded_terms.extend(synonyms)

        if expanded_terms:
            # ì¤‘ë³µ ì œê±°
            unique_terms = list(set(expanded_terms))
            expanded_query = f"{query} {' '.join(unique_terms)}"
            logger.debug(f"ğŸ“ ì¿¼ë¦¬ í™•ì¥: '{query}' â†’ '{expanded_query}'")
            return expanded_query

        return query

    async def encode(self, text: str, expand: bool = True) -> Dict[str, Any]:
        """í…ìŠ¤íŠ¸ë¥¼ BGE-M3 Sparse ë²¡í„°ë¡œ ì¸ì½”ë”©

        Args:
            text: ì¸ì½”ë”©í•  í…ìŠ¤íŠ¸
            expand: ì¿¼ë¦¬ í™•ì¥ ì—¬ë¶€ (ê¸°ë³¸ True)

        Returns:
            Sparse ë²¡í„° ë”•ì…”ë„ˆë¦¬ {"indices": [...], "values": [...]}
        """
        if not self._initialized:
            await self.initialize()

        if not self.model:
            logger.error("BGE-M3 ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return {"indices": [], "values": []}

        # ì¿¼ë¦¬ í™•ì¥ ì ìš©
        if expand:
            text = self.expand_query(text)

        try:
            loop = asyncio.get_event_loop()

            def do_encode():
                # BGE-M3 ì¸ì½”ë”© (sparseë§Œ í•„ìš”)
                output = self.model.encode(
                    [text],
                    return_dense=False,
                    return_sparse=True,
                    return_colbert_vecs=False,
                )
                return output

            output = await loop.run_in_executor(None, do_encode)

            # lexical_weightsì—ì„œ sparse ë²¡í„° ì¶”ì¶œ
            # í˜•ì‹: {token_id: weight, ...}
            lexical_weights = output.get("lexical_weights", [{}])[0]

            if not lexical_weights:
                return {"indices": [], "values": []}

            # ë”•ì…”ë„ˆë¦¬ë¥¼ indices/values í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            indices = list(lexical_weights.keys())
            values = list(lexical_weights.values())

            return {
                "indices": indices,
                "values": values,
            }

        except Exception as e:
            logger.error(f"âŒ BGE-M3 ì¸ì½”ë”© ì‹¤íŒ¨: {e}")
            return {"indices": [], "values": []}

    async def encode_batch(
        self,
        texts: List[str],
        batch_size: int = 8,
    ) -> List[Dict[str, Any]]:
        """í…ìŠ¤íŠ¸ ë°°ì¹˜ë¥¼ BGE-M3 Sparse ë²¡í„°ë¡œ ì¸ì½”ë”©

        Args:
            texts: ì¸ì½”ë”©í•  í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
            batch_size: ë°°ì¹˜ í¬ê¸° (ë©”ëª¨ë¦¬ ì œì•½ìœ¼ë¡œ 8 ê¶Œì¥)

        Returns:
            Sparse ë²¡í„° ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
        """
        if not self._initialized:
            await self.initialize()

        if not self.model:
            logger.error("BGE-M3 ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return [{"indices": [], "values": []} for _ in texts]

        results = []

        for i in range(0, len(texts), batch_size):
            batch_texts = texts[i:i + batch_size]

            try:
                loop = asyncio.get_event_loop()

                def do_encode_batch(batch):
                    output = self.model.encode(
                        batch,
                        return_dense=False,
                        return_sparse=True,
                        return_colbert_vecs=False,
                    )
                    return output

                output = await loop.run_in_executor(
                    None, do_encode_batch, batch_texts
                )

                # ê° ë¬¸ì„œì˜ lexical_weights ì²˜ë¦¬
                lexical_weights_list = output.get("lexical_weights", [])

                for lexical_weights in lexical_weights_list:
                    if not lexical_weights:
                        results.append({"indices": [], "values": []})
                        continue

                    indices = list(lexical_weights.keys())
                    values = list(lexical_weights.values())

                    results.append({
                        "indices": indices,
                        "values": values,
                    })

                logger.info(
                    f"ğŸ“ BGE-M3 ë°°ì¹˜ ì¸ì½”ë”©: {i + len(batch_texts)}/{len(texts)} ì™„ë£Œ"
                )

            except Exception as e:
                logger.error(f"âŒ BGE-M3 ë°°ì¹˜ ì¸ì½”ë”© ì‹¤íŒ¨: {e}")
                # ì‹¤íŒ¨í•œ ë°°ì¹˜ëŠ” ë¹ˆ ë²¡í„°ë¡œ ì±„ì›€
                results.extend([{"indices": [], "values": []} for _ in batch_texts])

        logger.info(f"âœ… BGE-M3 ì „ì²´ ì¸ì½”ë”© ì™„ë£Œ: {len(results)}ê°œ")
        return results

    def get_sparse_score(self, sparse_vector: Dict[str, Any]) -> float:
        """Sparse ë²¡í„°ì˜ ì´ ì ìˆ˜ ê³„ì‚°

        Args:
            sparse_vector: sparse ë²¡í„°

        Returns:
            ì´ ì ìˆ˜ (values í•©ê³„)
        """
        values = sparse_vector.get("values", [])
        return sum(values) if values else 0.0

    def normalize_score(self, score: float) -> float:
        """ì ìˆ˜ë¥¼ 0~1 ë²”ìœ„ë¡œ ì •ê·œí™”

        Args:
            score: ì›ë³¸ ì ìˆ˜

        Returns:
            0~1 ë²”ìœ„ë¡œ ì •ê·œí™”ëœ ì ìˆ˜
        """
        normalized = score / self.max_score
        return min(normalized, 1.0)

    async def create_document_text(
        self,
        item_name: str,
        efficacy: Optional[str] = None,
        use_method: Optional[str] = None,
        caution_info: Optional[str] = None,
    ) -> str:
        """ì¸ë±ì‹±ìš© ë¬¸ì„œ í…ìŠ¤íŠ¸ ìƒì„±

        Args:
            item_name: ì œí’ˆëª…
            efficacy: íš¨ëŠ¥íš¨ê³¼
            use_method: ìš©ë²•ìš©ëŸ‰
            caution_info: ì£¼ì˜ì‚¬í•­

        Returns:
            ì¸ì½”ë”©ìš© í…ìŠ¤íŠ¸
        """
        parts = [item_name or ""]

        if efficacy:
            parts.append(efficacy)
        if use_method:
            parts.append(use_method[:300])  # ìš©ë²•ì€ ì•ë¶€ë¶„ë§Œ
        if caution_info:
            parts.append(caution_info[:200])  # ì£¼ì˜ì‚¬í•­ë„ ì•ë¶€ë¶„ë§Œ

        return " ".join(parts)


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_splade_service: Optional[SPLADEService] = None


def get_splade_service() -> SPLADEService:
    """Sparse Embedding ì„œë¹„ìŠ¤ ì‹±ê¸€í†¤ ë°˜í™˜"""
    global _splade_service
    if _splade_service is None:
        _splade_service = SPLADEService()
    return _splade_service


async def initialize_splade() -> bool:
    """Sparse Embedding ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
    if not settings.ENABLE_MILVUS:
        logger.info("âš ï¸ BGE-M3 ë¹„í™œì„±í™”ë¨ (ENABLE_MILVUS=false)")
        return False

    service = get_splade_service()
    return await service.initialize()
