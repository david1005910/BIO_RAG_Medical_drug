"""Milvus ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì„œë¹„ìŠ¤ - Dense + Sparse Hybrid Search ì§€ì›"""
import logging
import uuid
from dataclasses import dataclass
from typing import Any, Dict, List, Optional

from pymilvus import (
    Collection,
    CollectionSchema,
    DataType,
    FieldSchema,
    MilvusClient,
    connections,
    utility,
)

from app.core.config import settings

logger = logging.getLogger(__name__)


@dataclass
class MilvusSearchResult:
    """Milvus ê²€ìƒ‰ ê²°ê³¼"""

    drug_id: str
    item_name: str
    entp_name: str
    efficacy: str
    use_method: Optional[str]
    caution_info: Optional[str]
    side_effects: Optional[str]
    dense_score: float
    sparse_score: float
    hybrid_score: float


class MilvusService:
    """Milvus ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì„œë¹„ìŠ¤

    Dense Vector (OpenAI Embedding) + Sparse Vector (BGE-M3) í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì§€ì›
    """

    # Field names
    DENSE_VECTOR_NAME = "dense"
    SPARSE_VECTOR_NAME = "sparse"

    def __init__(
        self,
        uri: Optional[str] = None,
        collection_name: Optional[str] = None,
        token: Optional[str] = None,
    ):
        self.uri = uri or settings.MILVUS_URI
        self.collection_name = collection_name or settings.MILVUS_COLLECTION_NAME
        self.token = token or settings.MILVUS_TOKEN
        self.client: Optional[MilvusClient] = None
        self._initialized = False

    async def connect(self) -> bool:
        """Milvus ì„œë²„ì— ì—°ê²°

        Returns:
            ì—°ê²° ì„±ê³µ ì—¬ë¶€
        """
        try:
            # MilvusClient API ì‚¬ìš© (pymilvus 2.4+)
            self.client = MilvusClient(
                uri=self.uri,
                token=self.token if self.token else None,
            )

            # ì—°ê²° í…ŒìŠ¤íŠ¸
            collections = self.client.list_collections()
            logger.info(f"âœ… Milvus ì—°ê²° ì„±ê³µ: {self.uri}")
            logger.info(f"ğŸ“š ê¸°ì¡´ ì»¬ë ‰ì…˜: {collections}")
            self._initialized = True
            return True
        except Exception as e:
            logger.error(f"âŒ Milvus ì—°ê²° ì‹¤íŒ¨: {e}")
            self._initialized = False
            return False

    async def create_collection(
        self,
        dense_dim: int = 1536,
        recreate: bool = False,
    ) -> bool:
        """ì»¬ë ‰ì…˜ ìƒì„± (Dense + Sparse ë²¡í„°)

        Args:
            dense_dim: Dense ë²¡í„° ì°¨ì› (OpenAI embedding: 1536)
            recreate: ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ í›„ ì¬ìƒì„± ì—¬ë¶€

        Returns:
            ìƒì„± ì„±ê³µ ì—¬ë¶€
        """
        if not self.client:
            await self.connect()

        try:
            # ê¸°ì¡´ ì»¬ë ‰ì…˜ í™•ì¸
            if self.client.has_collection(self.collection_name):
                if recreate:
                    logger.info(f"ğŸ—‘ï¸ ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ: {self.collection_name}")
                    self.client.drop_collection(self.collection_name)
                else:
                    logger.info(f"ğŸ“š ì»¬ë ‰ì…˜ ì´ë¯¸ ì¡´ì¬: {self.collection_name}")
                    return True

            # ìŠ¤í‚¤ë§ˆ ì •ì˜
            schema = self.client.create_schema(
                auto_id=False,
                enable_dynamic_field=True,
            )

            # Primary Key - drug_idì˜ UUID5 í•´ì‹œ
            schema.add_field(
                field_name="id",
                datatype=DataType.VARCHAR,
                is_primary=True,
                max_length=64,
            )

            # ë©”íƒ€ë°ì´í„° í•„ë“œ
            schema.add_field(
                field_name="drug_id",
                datatype=DataType.VARCHAR,
                max_length=64,
            )
            schema.add_field(
                field_name="item_name",
                datatype=DataType.VARCHAR,
                max_length=500,
            )
            schema.add_field(
                field_name="entp_name",
                datatype=DataType.VARCHAR,
                max_length=500,
            )
            schema.add_field(
                field_name="efficacy",
                datatype=DataType.VARCHAR,
                max_length=10000,
            )
            schema.add_field(
                field_name="use_method",
                datatype=DataType.VARCHAR,
                max_length=10000,
            )
            schema.add_field(
                field_name="caution_info",
                datatype=DataType.VARCHAR,
                max_length=10000,
            )
            schema.add_field(
                field_name="side_effects",
                datatype=DataType.VARCHAR,
                max_length=10000,
            )

            # Dense ë²¡í„° í•„ë“œ (OpenAI embedding)
            schema.add_field(
                field_name=self.DENSE_VECTOR_NAME,
                datatype=DataType.FLOAT_VECTOR,
                dim=dense_dim,
            )

            # Sparse ë²¡í„° í•„ë“œ (BGE-M3)
            schema.add_field(
                field_name=self.SPARSE_VECTOR_NAME,
                datatype=DataType.SPARSE_FLOAT_VECTOR,
            )

            # ì¸ë±ìŠ¤ íŒŒë¼ë¯¸í„°
            index_params = self.client.prepare_index_params()

            # Dense ë²¡í„° ì¸ë±ìŠ¤ (HNSW for cosine similarity)
            index_params.add_index(
                field_name=self.DENSE_VECTOR_NAME,
                index_type="HNSW",
                metric_type="COSINE",
                params={"M": 16, "efConstruction": 200},
            )

            # Sparse ë²¡í„° ì¸ë±ìŠ¤
            index_params.add_index(
                field_name=self.SPARSE_VECTOR_NAME,
                index_type="SPARSE_INVERTED_INDEX",
                metric_type="IP",  # Inner Product for sparse
                params={"drop_ratio_build": 0.2},
            )

            # ì»¬ë ‰ì…˜ ìƒì„±
            self.client.create_collection(
                collection_name=self.collection_name,
                schema=schema,
                index_params=index_params,
            )

            logger.info(f"âœ… ì»¬ë ‰ì…˜ ìƒì„± ì™„ë£Œ: {self.collection_name}")
            logger.info(f"   - Dense ë²¡í„°: {dense_dim}ì°¨ì›, HNSW, Cosine")
            logger.info(f"   - Sparse ë²¡í„°: SPARSE_INVERTED_INDEX, IP")
            return True

        except Exception as e:
            logger.error(f"âŒ ì»¬ë ‰ì…˜ ìƒì„± ì‹¤íŒ¨: {e}")
            return False

    async def upsert_documents(
        self,
        documents: List[Dict[str, Any]],
        dense_vectors: List[List[float]],
        sparse_vectors: List[Dict[str, Any]],  # {"indices": [...], "values": [...]}
        batch_size: int = 100,
    ) -> int:
        """ë¬¸ì„œ ë° ë²¡í„° ì—…ì„œíŠ¸

        Args:
            documents: ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ë¦¬ìŠ¤íŠ¸
            dense_vectors: Dense ë²¡í„° ë¦¬ìŠ¤íŠ¸ (OpenAI embedding)
            sparse_vectors: Sparse ë²¡í„° ë¦¬ìŠ¤íŠ¸ (BGE-M3)
            batch_size: ë°°ì¹˜ í¬ê¸°

        Returns:
            ì—…ì„œíŠ¸ëœ ë¬¸ì„œ ìˆ˜
        """
        if not self.client:
            await self.connect()

        if len(documents) != len(dense_vectors) or len(documents) != len(sparse_vectors):
            logger.error("ë¬¸ì„œ, Dense ë²¡í„°, Sparse ë²¡í„° ìˆ˜ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return 0

        total_upserted = 0

        for i in range(0, len(documents), batch_size):
            batch_docs = documents[i : i + batch_size]
            batch_dense = dense_vectors[i : i + batch_size]
            batch_sparse = sparse_vectors[i : i + batch_size]

            data = []
            for j, (doc, dense, sparse) in enumerate(
                zip(batch_docs, batch_dense, batch_sparse)
            ):
                # drug_idë¥¼ UUID5ë¡œ ë³€í™˜
                drug_id = str(doc.get("drug_id", f"doc_{i + j}"))
                point_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, drug_id))

                # Sparse ë²¡í„°ë¥¼ Milvus í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                # Milvus expects {index: value, ...} dict format
                sparse_dict = {}
                indices = sparse.get("indices", [])
                values = sparse.get("values", [])
                for idx, val in zip(indices, values):
                    sparse_dict[int(idx)] = float(val)

                # ë¬¸ìì—´ ê¸¸ì´ ì œí•œ ì ìš©
                data.append(
                    {
                        "id": point_id,
                        "drug_id": drug_id,
                        "item_name": str(doc.get("item_name", ""))[:500],
                        "entp_name": str(doc.get("entp_name", ""))[:500],
                        "efficacy": str(doc.get("efficacy", ""))[:10000],
                        "use_method": str(doc.get("use_method", ""))[:10000],
                        "caution_info": str(doc.get("caution_info", ""))[:10000],
                        "side_effects": str(doc.get("side_effects", ""))[:10000],
                        self.DENSE_VECTOR_NAME: dense,
                        self.SPARSE_VECTOR_NAME: sparse_dict,
                    }
                )

            try:
                self.client.upsert(
                    collection_name=self.collection_name,
                    data=data,
                )
                total_upserted += len(data)
                logger.info(f"ğŸ“ ë°°ì¹˜ ì—…ì„œíŠ¸: {len(data)}ê°œ (ì´ {total_upserted}ê°œ)")
            except Exception as e:
                logger.error(f"âŒ ë°°ì¹˜ ì—…ì„œíŠ¸ ì‹¤íŒ¨: {e}")

        logger.info(f"âœ… ì „ì²´ ì—…ì„œíŠ¸ ì™„ë£Œ: {total_upserted}ê°œ")
        return total_upserted

    async def hybrid_search(
        self,
        dense_vector: List[float],
        sparse_vector: Dict[str, Any],  # {"indices": [...], "values": [...]}
        top_k: int = 10,
        dense_weight: float = 0.7,
        sparse_weight: float = 0.3,
    ) -> List[MilvusSearchResult]:
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (Dense + Sparse)

        ì ìˆ˜ ì²´ê³„:
        - Dense Score: 0~1 (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)
        - Sparse Score: BGE-M3 ì ìˆ˜ë¥¼ 0~10 ê¸°ì¤€ìœ¼ë¡œ 0~1 ì •ê·œí™”
        - Hybrid Score: dense * 0.7 + sparse * 0.3

        Args:
            dense_vector: ì¿¼ë¦¬ Dense ë²¡í„° (OpenAI embedding)
            sparse_vector: ì¿¼ë¦¬ Sparse ë²¡í„° (BGE-M3)
            top_k: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
            dense_weight: Dense ê°€ì¤‘ì¹˜ (ê¸°ë³¸ 0.7)
            sparse_weight: Sparse ê°€ì¤‘ì¹˜ (ê¸°ë³¸ 0.3)

        Returns:
            í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        if not self.client:
            await self.connect()

        try:
            # Sparse ë²¡í„°ë¥¼ Milvus í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            sparse_dict = {}
            indices = sparse_vector.get("indices", [])
            values = sparse_vector.get("values", [])
            for idx, val in zip(indices, values):
                sparse_dict[int(idx)] = float(val)

            # ì¶œë ¥ í•„ë“œ
            output_fields = [
                "drug_id",
                "item_name",
                "entp_name",
                "efficacy",
                "use_method",
                "caution_info",
                "side_effects",
            ]

            # Dense ê²€ìƒ‰ ìˆ˜í–‰
            dense_results = self.client.search(
                collection_name=self.collection_name,
                data=[dense_vector],
                anns_field=self.DENSE_VECTOR_NAME,
                search_params={"metric_type": "COSINE", "params": {"ef": 100}},
                limit=top_k * 2,
                output_fields=output_fields,
            )

            # Sparse ê²€ìƒ‰ ìˆ˜í–‰
            sparse_results = self.client.search(
                collection_name=self.collection_name,
                data=[sparse_dict],
                anns_field=self.SPARSE_VECTOR_NAME,
                search_params={"metric_type": "IP", "params": {"drop_ratio_search": 0.2}},
                limit=top_k * 2,
                output_fields=output_fields,
            )

            # ê²°ê³¼ ë³‘í•© ë° í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ê³„ì‚°
            results_map: Dict[str, Dict] = {}

            # Dense ê²°ê³¼ ì²˜ë¦¬
            if dense_results and len(dense_results) > 0:
                for hit in dense_results[0]:
                    entity = hit.get("entity", {})
                    drug_id = entity.get("drug_id", str(hit.get("id", "")))
                    # Cosine similarity score
                    dense_score = float(hit.get("distance", 0))

                    results_map[drug_id] = {
                        "entity": entity,
                        "id": hit.get("id"),
                        "dense_score": dense_score,
                        "sparse_score": 0.0,
                    }

            # Sparse ê²°ê³¼ ì²˜ë¦¬
            splade_max_score = settings.SPLADE_MAX_SCORE

            if sparse_results and len(sparse_results) > 0:
                for hit in sparse_results[0]:
                    entity = hit.get("entity", {})
                    drug_id = entity.get("drug_id", str(hit.get("id", "")))
                    raw_sparse_score = float(hit.get("distance", 0))
                    sparse_score = min(raw_sparse_score / splade_max_score, 1.0)

                    if drug_id in results_map:
                        results_map[drug_id]["sparse_score"] = sparse_score
                    else:
                        results_map[drug_id] = {
                            "entity": entity,
                            "id": hit.get("id"),
                            "dense_score": 0.0,
                            "sparse_score": sparse_score,
                        }

            # í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ê³„ì‚° ë° ê²°ê³¼ ìƒì„±
            hybrid_results = []
            for drug_id, data in results_map.items():
                dense_score = data["dense_score"]
                sparse_score = data["sparse_score"]

                # Hybrid Score = sparse * weight + dense * weight
                hybrid_score = sparse_weight * sparse_score + dense_weight * dense_score

                entity = data.get("entity", {})
                hybrid_results.append(
                    MilvusSearchResult(
                        drug_id=entity.get("drug_id", drug_id),
                        item_name=entity.get("item_name", ""),
                        entp_name=entity.get("entp_name", ""),
                        efficacy=entity.get("efficacy", ""),
                        use_method=entity.get("use_method"),
                        caution_info=entity.get("caution_info"),
                        side_effects=entity.get("side_effects"),
                        dense_score=dense_score,
                        sparse_score=sparse_score,
                        hybrid_score=hybrid_score,
                    )
                )

            # í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ë¡œ ì •ë ¬
            hybrid_results.sort(key=lambda x: x.hybrid_score, reverse=True)

            logger.info(
                f"ğŸ”€ Milvus Hybrid ê²€ìƒ‰ ì™„ë£Œ: "
                f"Dense={len(dense_results[0]) if dense_results else 0}, "
                f"Sparse={len(sparse_results[0]) if sparse_results else 0}, "
                f"Merged={len(hybrid_results[:top_k])}"
            )

            return hybrid_results[:top_k]

        except Exception as e:
            logger.error(f"âŒ Milvus Hybrid ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    async def dense_search(
        self,
        dense_vector: List[float],
        top_k: int = 10,
    ) -> List[Dict[str, Any]]:
        """Dense ë²¡í„° ê²€ìƒ‰ë§Œ ìˆ˜í–‰

        Args:
            dense_vector: ì¿¼ë¦¬ Dense ë²¡í„°
            top_k: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜

        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        if not self.client:
            await self.connect()

        try:
            output_fields = [
                "drug_id",
                "item_name",
                "entp_name",
                "efficacy",
                "use_method",
                "caution_info",
                "side_effects",
            ]

            results = self.client.search(
                collection_name=self.collection_name,
                data=[dense_vector],
                anns_field=self.DENSE_VECTOR_NAME,
                search_params={"metric_type": "COSINE", "params": {"ef": 100}},
                limit=top_k,
                output_fields=output_fields,
            )

            if results and len(results) > 0:
                return [
                    {
                        "drug_id": hit.get("entity", {}).get(
                            "drug_id", str(hit.get("id", ""))
                        ),
                        "similarity": float(hit.get("distance", 0)),
                        "dense_score": float(hit.get("distance", 0)),
                        **hit.get("entity", {}),
                    }
                    for hit in results[0]
                ]
            return []

        except Exception as e:
            logger.error(f"âŒ Dense ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    async def get_collection_info(self) -> Optional[Dict]:
        """ì»¬ë ‰ì…˜ ì •ë³´ ì¡°íšŒ"""
        if not self.client:
            await self.connect()

        try:
            stats = self.client.get_collection_stats(self.collection_name)
            return {
                "name": self.collection_name,
                "points_count": stats.get("row_count", 0),
                "vectors_count": stats.get("row_count", 0),
                "status": "ready",
            }
        except Exception as e:
            logger.error(f"âŒ ì»¬ë ‰ì…˜ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None

    async def delete_collection(self) -> bool:
        """ì»¬ë ‰ì…˜ ì‚­ì œ"""
        if not self.client:
            await self.connect()

        try:
            self.client.drop_collection(self.collection_name)
            logger.info(f"ğŸ—‘ï¸ ì»¬ë ‰ì…˜ ì‚­ì œ ì™„ë£Œ: {self.collection_name}")
            return True
        except Exception as e:
            logger.error(f"âŒ ì»¬ë ‰ì…˜ ì‚­ì œ ì‹¤íŒ¨: {e}")
            return False


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_milvus_service: Optional[MilvusService] = None


def get_milvus_service() -> MilvusService:
    """Milvus ì„œë¹„ìŠ¤ ì‹±ê¸€í†¤ ë°˜í™˜"""
    global _milvus_service
    if _milvus_service is None:
        _milvus_service = MilvusService()
    return _milvus_service


async def initialize_milvus() -> bool:
    """Milvus ì´ˆê¸°í™” - ì—°ê²° ë° ì»¬ë ‰ì…˜ ìƒì„±"""
    if not settings.ENABLE_MILVUS:
        logger.info("âš ï¸ Milvus ë¹„í™œì„±í™”ë¨ (ENABLE_MILVUS=false)")
        return False

    service = get_milvus_service()
    connected = await service.connect()

    if connected:
        await service.create_collection(
            dense_dim=settings.EMBEDDING_DIMENSIONS,
            recreate=False,
        )
        return True

    return False
